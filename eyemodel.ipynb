{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1770390,"sourceType":"datasetVersion","datasetId":1048759}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport torch\nimport random\nimport numpy as np\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom torchvision import transforms\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-23T14:13:19.498052Z","iopub.execute_input":"2025-04-23T14:13:19.498276Z","iopub.status.idle":"2025-04-23T14:13:28.845729Z","shell.execute_reply.started":"2025-04-23T14:13:19.498257Z","shell.execute_reply":"2025-04-23T14:13:28.844765Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"class EyeDataset(Dataset):\n    def __init__(self, folder_path, split='train', val_split=0.2, img_size=(86, 86)):\n        self.data = []\n        self.labels = []\n        self.img_size = img_size\n        self.label_map = {'Closed_Eyes': 0, 'Open_Eyes': 1}\n\n        for label in self.label_map:\n            path = os.path.join(folder_path, label)\n            for img_name in os.listdir(path):\n                img_path = os.path.join(path, img_name)\n                img = cv2.imread(img_path)\n                if img is None:\n                    continue\n                img = cv2.resize(img, self.img_size)\n                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n                self.data.append(img)\n                self.labels.append(self.label_map[label])\n\n        # Split\n        X_train, X_val, y_train, y_val = train_test_split(\n            self.data, self.labels, test_size=val_split, stratify=self.labels, random_state=42\n        )\n\n        if split == 'train':\n            self.data = X_train\n            self.labels = y_train\n        else:\n            self.data = X_val\n            self.labels = y_val\n\n        self.transform = transforms.Compose([\n            transforms.ToTensor(),               # Converts to [0, 1] tensor\n            transforms.Normalize([0.5], [0.5])  # Normalize to [-1, 1]\n        ])\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img = self.data[idx]\n        label = self.labels[idx]\n        img = self.transform(img)\n        return img, torch.tensor(label, dtype=torch.long)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T14:18:44.136780Z","iopub.execute_input":"2025-04-23T14:18:44.137283Z","iopub.status.idle":"2025-04-23T14:18:44.146990Z","shell.execute_reply.started":"2025-04-23T14:18:44.137254Z","shell.execute_reply":"2025-04-23T14:18:44.145999Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class EyeCNN(nn.Module):\n    def __init__(self):\n        super(EyeCNN, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=3, padding=1),  # [3,86,86] → [16,86,86]\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),                         # → [16,43,43]\n\n            nn.Conv2d(16, 32, kernel_size=3, padding=1),# → [32,43,43]\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),                         # → [32,21,21]\n\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),# → [64,21,21]\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2)                          # → [64,10,10]\n        )\n\n        self.fc = nn.Sequential(\n            nn.Flatten(),                               # → [6400]\n            nn.Linear(64 * 10 * 10, 128),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(128, 2)                           # Output: open or closed\n        )\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.fc(x)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T14:21:23.619192Z","iopub.execute_input":"2025-04-23T14:21:23.619487Z","iopub.status.idle":"2025-04-23T14:21:23.627277Z","shell.execute_reply.started":"2025-04-23T14:21:23.619468Z","shell.execute_reply":"2025-04-23T14:21:23.626135Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load dataset\ntrain_ds = EyeDataset(\"/kaggle/input/mrl-dataset/train\", split='train')\nval_ds   = EyeDataset(\"/kaggle/input/mrl-dataset/train\", split='val')\n\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\nval_loader   = DataLoader(val_ds, batch_size=32)\n\nmodel = EyeCNN().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T14:21:26.688190Z","iopub.execute_input":"2025-04-23T14:21:26.688485Z","iopub.status.idle":"2025-04-23T14:21:41.210355Z","shell.execute_reply.started":"2025-04-23T14:21:26.688464Z","shell.execute_reply":"2025-04-23T14:21:41.209495Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"for epoch in range(10):\n    model.train()\n    train_loss, train_correct = 0, 0\n\n    for imgs, labels in train_loader:\n        imgs, labels = imgs.to(device), labels.to(device)\n\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n        train_correct += (outputs.argmax(1) == labels).sum().item()\n\n    acc = train_correct / len(train_ds)\n    print(f\"Epoch {epoch+1} - Train Loss: {train_loss:.4f}, Accuracy: {acc:.4f}\")\n\n    # Validation\n    model.eval()\n    val_correct = 0\n    with torch.no_grad():\n        for imgs, labels in val_loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            outputs = model(imgs)\n            val_correct += (outputs.argmax(1) == labels).sum().item()\n\n    val_acc = val_correct / len(val_ds)\n    print(f\"Validation Accuracy: {val_acc:.4f}\\n\")\n\ntorch.save(model.state_dict(), \"eye_cnn_model.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T14:21:45.020868Z","iopub.execute_input":"2025-04-23T14:21:45.021170Z","iopub.status.idle":"2025-04-23T14:23:34.139134Z","shell.execute_reply.started":"2025-04-23T14:21:45.021149Z","shell.execute_reply":"2025-04-23T14:23:34.138232Z"}},"outputs":[{"name":"stdout","text":"Epoch 1 - Train Loss: 18.8398, Accuracy: 0.9116\nValidation Accuracy: 0.9762\n\nEpoch 2 - Train Loss: 4.3594, Accuracy: 0.9891\nValidation Accuracy: 0.9825\n\nEpoch 3 - Train Loss: 2.3838, Accuracy: 0.9938\nValidation Accuracy: 0.9900\n\nEpoch 4 - Train Loss: 2.6677, Accuracy: 0.9919\nValidation Accuracy: 0.9938\n\nEpoch 5 - Train Loss: 1.6122, Accuracy: 0.9962\nValidation Accuracy: 0.9950\n\nEpoch 6 - Train Loss: 0.6944, Accuracy: 0.9978\nValidation Accuracy: 1.0000\n\nEpoch 7 - Train Loss: 0.4920, Accuracy: 0.9988\nValidation Accuracy: 1.0000\n\nEpoch 8 - Train Loss: 0.3097, Accuracy: 0.9991\nValidation Accuracy: 1.0000\n\nEpoch 9 - Train Loss: 0.4267, Accuracy: 0.9988\nValidation Accuracy: 1.0000\n\nEpoch 10 - Train Loss: 0.2988, Accuracy: 0.9988\nValidation Accuracy: 1.0000\n\n","output_type":"stream"}],"execution_count":22}]}